# Rule: Generating a Task List from User Requirements

## Goal

To guide an AI assistant in creating a detailed, step-by-step task list in Markdown format based on user requirements, feature requests, or existing documentation. The task list should guide a developer through implementation.

## Output

- **Format:** Markdown (`.md`)
- **Location:** `/tasks/`
- **Filename:** `tasks-[feature-name].md` (e.g., `tasks-user-profile-editing.md`)

## Process

1.  **Receive Requirements:** The user provides a feature request, task description, or points to existing documentation
2.  **Analyze Requirements:** The AI analyzes the functional requirements, user needs, and implementation scope from the provided information
3.  **Identify Parallel Opportunities:** Check if tasks can be executed in parallel using the Decision Tree in "Task Workflow Optimization" section
4.  **Apply Templates if Applicable:** If requirements match common patterns (SSO, Docker, DB migration), use templates from "Template-Based Task Generation" section
5.  **Identify Relevant Files:** Based on the requirements, identify potential files that will need to be created or modified. List these under the `Relevant Files` section, including corresponding test files if applicable.
6.  **Generate Parent Tasks:** Based on the requirements analysis, create the main, high-level tasks required to implement the feature. **IMPORTANT: Always include task 0.0 "Create feature branch" as the first task, unless the user specifically requests not to create a branch.** Use your judgement on how many additional high-level tasks to use. It's likely to be about 5-7.
7.  **Generate Sub-Tasks:** Immediately break down each parent task into smaller, actionable sub-tasks necessary to complete the parent task. Ensure sub-tasks logically follow from the parent task and cover the implementation details implied by the requirements.
8.  **Add Parallel Group Markers:** For tasks identified in step 3, add `[PARALLEL GROUP: group-name]` markers to task titles
9.  **Generate Final Output:** Combine the parent tasks, sub-tasks, relevant files, and notes into the final Markdown structure in a single step.
10. **Save Task List:** Save the generated document in the `/tasks/` directory with the filename `tasks-[feature-name].md`, where `[feature-name]` describes the main feature or task being implemented (e.g., if the request was about user profile editing, the output is `tasks-user-profile-editing.md`).

## Parallel Execution Strategy

When generating tasks, identify and group parallel-executable work:

### 1. Parallel Work Identification

Check if tasks meet parallel criteria:
- ✅ **Independent repositories** (e.g., WBSalesHub + WBFinHub)
- ✅ **Independent Docker contexts** (separate builds)
- ✅ **Non-conflicting file changes** (different directories)
- ✅ **Shared API contract defined** (Backend + Frontend)

Mark with: `[PARALLEL GROUP: group-name]`

### 2. Parallel Task Grouping

**Example: Multi-Hub SSO Integration**
```markdown
## Tasks

- [ ] 1.0 [PARALLEL GROUP: hub-sso-integration] SSO Integration
  - [ ] 1.1 WBSalesHub SSO (Sub-Agent A)
    - [ ] 1.1.1 Update auth middleware
    - [ ] 1.1.2 Add JWT validation
  - [ ] 1.2 WBFinHub SSO (Sub-Agent B)
    - [ ] 1.2.1 Update auth middleware
    - [ ] 1.2.2 Add JWT validation
  - [ ] 1.3 WBOnboardingHub SSO (Sub-Agent C)
    - [ ] 1.3.1 Update auth middleware
    - [ ] 1.3.2 Add JWT validation
```

### 3. Sub-Agent Execution Pattern

For parallel groups:
1. **Phase 1: Setup** - Define API contracts, shared types
2. **Phase 2: Parallel Execution** - Launch sub-agents for independent work
3. **Phase 3: Integration** - Merge results, run integration tests

### 4. Test Parallelization

**Built-in Parallel Test Execution:**
- 단위 테스트: `workers: 4` (local), `workers: 2` (oracle)
- E2E 테스트: Reuse auth state for faster execution
- 통합 테스트: Parallel endpoint testing per Hub

**Test Groups:**
```markdown
- [ ] 5.0 [PARALLEL GROUP: qa-testing] QA Validation
  - [ ] 5.1 프론트엔드 빌드 검증 (Sub-Agent A)
  - [ ] 5.2 백엔드 빌드 검증 (Sub-Agent B)
  - [ ] 5.3 단위 테스트 실행 (Sub-Agent C, workers: 4)
  - [ ] 5.4 E2E 테스트 실행 (Sequential after 5.1-5.3)
```

## Template-Based Task Generation

For repeated patterns, use templates to accelerate task creation:

### Common Templates

#### 1. Multi-Hub SSO Integration Template
```markdown
- [ ] X.0 [PARALLEL GROUP: hub-sso] {HubName} SSO Integration
  - [ ] X.1 Update auth middleware (backend/middleware/auth.ts)
  - [ ] X.2 Add JWT validation (backend/utils/jwt.ts)
  - [ ] X.3 Update frontend auth context (frontend/contexts/AuthContext.tsx)
  - [ ] X.4 Add SSO tests (backend/tests/auth.test.ts)
```

**Apply to Hubs**: WBSalesHub, WBFinHub, WBOnboardingHub, WBRefHub

#### 2. Docker Build Optimization Template
```markdown
- [ ] X.0 {HubName} Docker Build Optimization
  - [ ] X.1 Add NODE_OPTIONS memory limit (Dockerfile:31)
  - [ ] X.2 Enable BuildKit cache (docker-compose.yml)
  - [ ] X.3 Verify build success (< 6GB memory)
```

#### 3. Database Migration Template
```markdown
- [ ] X.0 {HubName} Database Schema Update
  - [ ] X.1 Create Prisma migration (prisma/migrations/)
  - [ ] X.2 Update Prisma schema (prisma/schema.prisma)
  - [ ] X.3 Generate Prisma client (npx prisma generate)
  - [ ] X.4 Run migration (npx prisma migrate deploy)
  - [ ] X.5 Verify schema in PostgreSQL
```

### Template Variables
- `{HubName}`: WBHubManager, WBSalesHub, WBFinHub, etc.
- `{FeatureName}`: user-approval, sso-integration, etc.
- `{EntityName}`: Customer, Meeting, Transaction, etc.

### Usage
When requirements match a template pattern:
1. Identify the template category
2. Substitute variables
3. Add parallel group markers if applicable
4. Adjust for Hub-specific requirements

## Task Complexity Guidelines

### Automatic Task Count Warning (NEW)

AI will automatically monitor task count during generation:

**⚠️ Warning Trigger**: When task count exceeds 150
**AI Action**: Output warning message:
```
⚠️ Task count exceeds 150 (current: {count}).

Recommendations:
1. Split PRD into multiple feature PRDs (recommended for >200 tasks)
2. Merge granular sub-tasks (e.g., 2.2.1-2.2.5 → 2.2 Implement service)
3. Convert implementation details to inline descriptions

Proceed anyway? (y/n)
```

**Enforcement**:
- **Soft limit (150)**: AI warns but allows continuation
- **Hard limit (250)**: AI strongly recommends splitting PRD

### Atomic Task Principle
Each parent task should represent a **meaningful deliverable**, not implementation details.

**❌ Too Granular (Poor):**
```markdown
- [ ] 2.2 hubPermissions.service.ts 구현
  - [ ] 2.2.1 getUserHubPermissions(userId)
  - [ ] 2.2.2 grantHubPermission(userId, hubId, role)
  - [ ] 2.2.3 revokeHubPermission(userId, hubId)
```

**✅ Atomic Unit (Good):**
```markdown
- [ ] 2.2 Implement hubPermissions service
  - Description: Implement getUserHubPermissions, grantHubPermission, revokeHubPermission methods
  - File: `backend/services/hubPermissions.service.ts`
  - Tests: `backend/services/hubPermissions.service.test.ts`
```

### Complexity Targets
- **Simple feature**: 20-40 tasks (e.g., Docker build optimization)
- **Medium feature**: 40-80 tasks (e.g., Cookie auth migration)
- **Complex feature**: 80-120 tasks (e.g., Multi-hub system overhaul)

**⚠️ Warning**: If tasks exceed 150, consider splitting into multiple PRDs.

### Task Breakdown Formula
```
Total Tasks ≈ (DB Models × 3) + (API Endpoints × 2) + (UI Components × 2) + (Tests × 1.5) + QA Phase
```

## Task Workflow Optimization

### Sequential vs Parallel Decision Tree

```
Start: Is this task independent from other tasks?
├─ Yes: Can it be executed in parallel?
│  ├─ Yes: Different repository? → [PARALLEL GROUP: multi-hub]
│  ├─ Yes: Different Docker context? → [PARALLEL GROUP: builds]
│  ├─ Yes: Frontend + Backend after API contract? → [PARALLEL GROUP: implementation]
│  └─ No: Keep sequential
└─ No: Keep sequential (e.g., DB migration → schema update → tests)
```

### Critical Sequential Tasks (Never Parallelize)
1. **Database migrations**: Must complete before schema-dependent code
2. **Dependency installation**: Must complete before builds
3. **Authentication setup**: Must complete before protected endpoint tests
4. **Environment variable setup**: Must complete before Docker builds

### Optimal Parallel Patterns
1. **Multi-Hub identical changes**: Launch 3-4 sub-agents per Hub
2. **Build + Test**: Build (Agent A) || Tests (Agent B) if independent
3. **Frontend + Backend**: After API contract, parallel implementation
4. **Test suites**: Use workers (단위: 4, E2E: 2)

### Example: Optimal Task Flow

**Before (Sequential - 120min):**
```
1. Backend API (60min) → 2. Frontend UI (40min) → 3. Tests (20min)
```

**After (Parallel - 70min):**
```
1. API Contract Definition (10min)
   ↓
[PARALLEL GROUP] (60min)
├─ Agent A: Backend API (60min)
├─ Agent B: Frontend UI with mocks (40min)
└─ Agent C: Type definitions (20min)
   ↓
2. Integration Tests (Sequential, 20min)
```

**Time Saved: 50min (42% reduction)**

## Output Format

The generated task list _must_ follow this structure:

```markdown
## Relevant Files

- `path/to/potential/file1.ts:15-45` - Brief description of why this file is relevant (e.g., Contains the main component for this feature).
- `path/to/file1.test.ts` - Unit tests for `file1.ts`.
- `path/to/another/file.tsx:102-150` - Brief description (e.g., API route handler for data submission).
- `path/to/another/file.test.tsx` - Unit tests for `another/file.tsx`.
- `lib/utils/helpers.ts:30-60` - Brief description (e.g., Utility functions needed for calculations).
- `lib/utils/helpers.test.ts` - Unit tests for `helpers.ts`.

### Notes

- Unit tests should typically be placed alongside the code files they are testing (e.g., `MyComponent.tsx` and `MyComponent.test.tsx` in the same directory).
- Use `npx jest [optional/path/to/test/file]` to run tests. Running without a path executes all tests found by the Jest configuration.
- Include line numbers (e.g., `file.ts:15-45`) for files that need specific section modifications.
- Environment-specific test configurations are defined in "QA Testing & Server Management > 2. 환경별 테스트 전략" section.

## Instructions for Completing Tasks

**IMPORTANT:** As you complete each task, you must check it off in this markdown file by changing `- [ ]` to `- [x]`. This helps track progress and ensures you don't skip any steps.

Example:
- `- [ ] 1.1 Read file` → `- [x] 1.1 Read file` (after completing)

Update the file after completing each sub-task, not just after completing an entire parent task.

## Tasks

- [ ] 0.0 Create feature branch
  - [ ] 0.1 Create and checkout a new branch for this feature (e.g., `git checkout -b feature/[feature-name]`)
- [ ] 1.0 Parent Task Title
  - [ ] 1.1 [Sub-task description 1.1]
  - [ ] 1.2 [Sub-task description 1.2]
- [ ] 2.0 [PARALLEL GROUP: example-group] Parent Task with Parallel Sub-Tasks (if applicable)
  - [ ] 2.1 Sub-task A (Sub-Agent A)
  - [ ] 2.2 Sub-task B (Sub-Agent B)
  - [ ] 2.3 Integration (Sequential after 2.1-2.2)
- [ ] 3.0 Parent Task Title (may not require sub-tasks if purely structural or configuration)
```

## Interaction Model

The AI generates both parent tasks and detailed sub-tasks in a single step, creating a complete task list without requiring intermediate user confirmation. This allows for efficient task planning and immediate implementation.

## Target Audience

Assume the primary reader of the task list is a **junior developer** who will implement the feature.

## QA Testing & Server Management (Peter's Custom Rules)

### 1. 개발 후 QA 테스트 강화

개발 완료 후 반드시 아래 QA 테스트를 수행하고, 문제 발견 시 자체적으로 수정합니다:

- **빌드 검증**: 프론트엔드(`npm run build`)와 백엔드(`npm run build`) 빌드가 모두 성공하는지 확인
- **TypeScript 타입 검사**: 타입 에러가 없는지 확인하고, 있다면 수정
- **기능 테스트**: 구현된 기능이 정상 동작하는지 확인
- **에러 핸들링**: 예외 상황에서 적절한 에러 메시지가 표시되는지 확인
- **UI/UX 검증**: 레이아웃이 깨지지 않고 사용자 경험이 자연스러운지 확인

### 2. 환경별 테스트 전략 (Single Source of Truth)

**IMPORTANT**: 환경별 테스트 설정은 이 섹션에만 정의하며, 개별 테스크 파일은 이 섹션을 참조합니다.

#### Local Development (빠른 피드백)
- **단위 테스트**: timeout 15s, workers: 4, retries: 0
- **E2E 테스트**: timeout 30s, workers: 4, retries: 1
- **통합 테스트**: timeout 30s, parallel endpoint testing
- **Health Check**: 30초

#### Docker Staging (안정성 우선)
- **단위 테스트**: timeout 30s, workers: 2, retries: 1
- **E2E 테스트**: timeout 60s, workers: 2, retries: 2
- **통합 테스트**: timeout 60s, sequential execution
- **Health Check**: 60초 (Prisma migration 허용)

#### Oracle Production (최고 안정성)
- **단위 테스트**: timeout 60s, workers: 2, retries: 3
- **E2E 테스트**: timeout 90s, workers: 1, retries: 3
- **통합 테스트**: timeout 90s, sequential execution
- **Health Check**: 90초 (안정성 최우선)

#### 테스트 최적화
- **E2E Auth Reuse**: Playwright storage state로 Google OAuth 로그인 재사용 (30-60s 절약)
- **Frontend 404 테스트 제외**: Next.js Static Export는 모든 라우트에 200 반환
- **API 404 테스트만 유지**: Backend endpoint 404 검증

### 3. 서버 재시작 프로세스

전체 작업 완료 후, 아래 순서로 서버를 재시작합니다:

```bash
# 1. 기존 프로세스 강제 종료
# 포트 3000 (프론트엔드)
netstat -ano | grep 3000
powershell -Command "Stop-Process -Id [PID] -Force"

# 포트 4000 (백엔드)
netstat -ano | grep 4000
powershell -Command "Stop-Process -Id [PID] -Force"

# 2. lock 파일 제거 (필요시)
rm -rf frontend/.next/dev/lock

# 3. 백엔드 서버 시작
npm run dev:server

# 4. 프론트엔드 서버 시작
cd frontend && npm run dev
```

### 4. 프론트엔드 실행 전 보장 체크리스트

사용자가 프론트엔드를 실행하기 전, 아래 항목이 모두 충족되어야 합니다:

- [ ] 프론트엔드 빌드 성공 확인 (`npm run build`)
- [ ] 백엔드 빌드 성공 확인 (`npm run build`)
- [ ] 백엔드 서버 정상 구동 확인 (포트 4000)
- [ ] 프론트엔드 서버 정상 구동 확인 (포트 3000)
- [ ] 데이터베이스 연결 확인
- [ ] 로그인 기능 정상 동작 확인
- [ ] 주요 페이지 로딩 에러 없음 확인

**중요:** 위 체크리스트 중 하나라도 실패하면, 문제를 해결한 후 다시 검증해야 합니다.
